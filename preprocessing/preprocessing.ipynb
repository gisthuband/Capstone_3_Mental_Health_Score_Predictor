{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4830c6",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This is the third installment of the Capstone 3 project: Preprocessing\n",
    "Here are links to the other installments:\n",
    "\n",
    "Data Wrangle https://github.com/gisthuband/Capstone_3_Mental_Health_Score_Predictor/blob/main/data_wrangle/data_wrangle.ipynb\n",
    "\n",
    "Exploratory Data Analysis https://github.com/gisthuband/Capstone_3_Mental_Health_Score_Predictor/blob/main/exploratory_data_analysis/exploratory_data_analysis.ipynb\n",
    "\n",
    "\n",
    "\n",
    "This project will be used to predict the mental health scores of individuals based on race/ethnicity, the unemployment rate change, and the unemployment change.\n",
    "\n",
    "Inputs: Race/Ethnicity, unemployment rate change, unemployment change\n",
    "\n",
    "Outputs: Mental Health Score\n",
    "\n",
    "In this notebook I aim to come up with a preprocessing object that can be used in the modeling step of this project.\n",
    "\n",
    "What will the object be able to generate:\n",
    "\n",
    "1.) A dataframe with only numeric information\n",
    "\n",
    "2.) A dataframe with a one hot encoding of categorical variables\n",
    "\n",
    "3.) A numeric only dataframe that has random values\n",
    "\n",
    "4.) A one hot encoded dataframe that has random values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c437191",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b078c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb0c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('explored_data_v1.csv')\n",
    "df =df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf8effc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>Year</th>\n",
       "      <th>weighted_unemployment_rate_change</th>\n",
       "      <th>total_unemployed_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Symptoms of Depressive Disorder</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.168662</td>\n",
       "      <td>1771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Symptoms of Anxiety Disorder</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>36.3</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.168662</td>\n",
       "      <td>1771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Symptoms of Anxiety Disorder or Depressive Dis...</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>42.7</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.168662</td>\n",
       "      <td>1771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Symptoms of Depressive Disorder</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>27.9</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.168662</td>\n",
       "      <td>1771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Symptoms of Anxiety Disorder</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>36.2</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.168662</td>\n",
       "      <td>1771000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Indicator            Subgroup  \\\n",
       "0                    Symptoms of Depressive Disorder  Hispanic or Latino   \n",
       "1                       Symptoms of Anxiety Disorder  Hispanic or Latino   \n",
       "2  Symptoms of Anxiety Disorder or Depressive Dis...  Hispanic or Latino   \n",
       "3                    Symptoms of Depressive Disorder  Hispanic or Latino   \n",
       "4                       Symptoms of Anxiety Disorder  Hispanic or Latino   \n",
       "\n",
       "         Date  Value  Year  weighted_unemployment_rate_change  \\\n",
       "0  2020-04-23   29.4  2020                           6.168662   \n",
       "1  2020-04-23   36.3  2020                           6.168662   \n",
       "2  2020-04-23   42.7  2020                           6.168662   \n",
       "3  2020-05-07   27.9  2020                           6.168662   \n",
       "4  2020-05-07   36.2  2020                           6.168662   \n",
       "\n",
       "   total_unemployed_change  \n",
       "0                1771000.0  \n",
       "1                1771000.0  \n",
       "2                1771000.0  \n",
       "3                1771000.0  \n",
       "4                1771000.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15355799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self, df_path):\n",
    "        self.df_path = df_path\n",
    "    \n",
    "    \n",
    "    def numeric_only(df_path):\n",
    "        \n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "        df = df.drop(columns=['Date','Year','Indicator','Subgroup'])\n",
    "        \n",
    "        features = list(df.columns[df.columns != 'Value'])\n",
    "\n",
    "        X = df[features]\n",
    "        \n",
    "        y = df['Value']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=5)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def dummied(df_path):\n",
    "        \n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "        \n",
    "        df = df.drop(columns=['Date','Year'])\n",
    "        \n",
    "        dum_df = pd.get_dummies(df[['Indicator','Subgroup']])        \n",
    "        \n",
    "        dummed_df = pd.concat([df, dum_df],axis=1)\n",
    "\n",
    "        dummed_df = dummed_df.drop(columns=['Indicator','Subgroup'])\n",
    "        \n",
    "        features = list(dummed_df.columns[dummed_df.columns != 'Value'])\n",
    "        \n",
    "        X = dummed_df[features]\n",
    "\n",
    "        y = dummed_df['Value']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def random_label_numeric_only(df_path):\n",
    "        \n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "        df = df.drop(columns=['Date','Year','Indicator','Subgroup'])\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        rand_scores = list(rng.integers(low=0, high=48, size=len(df))) \n",
    "        \n",
    "        df['random_values'] = rand_scores\n",
    "        \n",
    "        df = df.drop(columns='Value')\n",
    "        \n",
    "        features = list(df.columns[df.columns != 'random_values'])\n",
    "\n",
    "        X = df[features]\n",
    "        \n",
    "        y = df['random_values']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=6)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def random_label_dum(df_path):\n",
    "        \n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "        \n",
    "        df = df.drop(columns=['Date','Year'])\n",
    "        \n",
    "        dum_df = pd.get_dummies(df[['Indicator','Subgroup']])        \n",
    "        \n",
    "        dummed_df = pd.concat([df, dum_df],axis=1)\n",
    "\n",
    "        dummed_df = dummed_df.drop(columns=['Indicator','Subgroup'])\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        rand_scores = list(rng.integers(low=0, high=48, size=len(df))) \n",
    "        \n",
    "        dummed_df['random_values'] = rand_scores\n",
    "        \n",
    "        dummed_df = dummed_df.drop(columns='Value')\n",
    "        \n",
    "        features = list(dummed_df.columns[dummed_df.columns != 'random_values'])\n",
    "\n",
    "        X = dummed_df[features]\n",
    "        \n",
    "        y = dummed_df['random_values']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=9)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86732abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_real = preprocess.dummied('explored_data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7caf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 9)\n",
      "(140, 9)\n",
      "(556,)\n",
      "(140,)\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print (trial_real[x].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07bc2d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78     29.5\n",
       "83     39.6\n",
       "690    22.3\n",
       "222    23.3\n",
       "154    25.9\n",
       "       ... \n",
       "298    26.6\n",
       "29     43.4\n",
       "151    29.1\n",
       "163    31.6\n",
       "97     30.2\n",
       "Name: Value, Length: 556, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_real[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56124bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_fake =preprocess.random_label_dum('explored_data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5575340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 9)\n",
      "(140, 9)\n",
      "(556,)\n",
      "(140,)\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print (trial_fake[x].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553fd933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88     27\n",
       "21     18\n",
       "608     6\n",
       "276    45\n",
       "504    13\n",
       "       ..\n",
       "56     31\n",
       "501     0\n",
       "638    14\n",
       "348     0\n",
       "382     9\n",
       "Name: random_values, Length: 556, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_fake[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786be9f",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "This notebook contains the class that will be used to train the models in the next step.\n",
    "\n",
    "There is now a dataframe containing only originally numeric information.\n",
    "\n",
    "Also there is now a dataframe containing one hot encoding of the categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3950b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
